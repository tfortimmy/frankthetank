{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Previous Winner\n",
    "https://github.com/ybabakhin/kaggle_salt_bes_phalanx/blob/master/bes/models/models_zoo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine.training import Model\n",
    "from keras.layers import SpatialDropout2D, Conv2D\n",
    "from segmentation_models import Unet\n",
    "\n",
    "\n",
    "def unet_resnext_50(input_shape, freeze_encoder, classes=4):\n",
    "    resnet_base, hyper_list = Unet(backbone_name='resnext50',\n",
    "                                   input_shape=input_shape,\n",
    "                                   input_tensor=None,\n",
    "                                   encoder_weights='imagenet',\n",
    "                                   freeze_encoder=freeze_encoder,\n",
    "                                   skip_connections='default',\n",
    "                                   decoder_block_type='transpose',\n",
    "                                   decoder_filters=(128, 64, 32, 16, 8),\n",
    "                                   decoder_use_batchnorm=True,\n",
    "                                   n_upsample_blocks=5,\n",
    "                                   upsample_rates=(2, 2, 2, 2, 2),\n",
    "                                   classes=classes,\n",
    "                                   activation='sigmoid')\n",
    "\n",
    "    x = SpatialDropout2D(0.2)(resnet_base.output)\n",
    "    x = Conv2D(1, (1, 1), activation=\"sigmoid\", name=\"prediction\")(x)\n",
    "\n",
    "    model = Model(resnet_base.input, x)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def unet_resnext_50_lovasz(input_shape, freeze_encoder, classes=4):\n",
    "    resnet_base, hyper_list = Unet(backbone_name='resnext50',\n",
    "                                   input_shape=input_shape,\n",
    "                                   input_tensor=None,\n",
    "                                   encoder_weights='imagenet',\n",
    "                                   freeze_encoder=freeze_encoder,\n",
    "                                   skip_connections='default',\n",
    "                                   decoder_block_type='transpose',\n",
    "                                   decoder_filters=(128, 64, 32, 16, 8),\n",
    "                                   decoder_use_batchnorm=True,\n",
    "                                   n_upsample_blocks=5,\n",
    "                                   upsample_rates=(2, 2, 2, 2, 2),\n",
    "                                   classes=classes,\n",
    "                                   activation='sigmoid')\n",
    "\n",
    "    x = SpatialDropout2D(0.2)(resnet_base.output)\n",
    "    x = Conv2D(1, (1, 1), name=\"prediction\")(x)\n",
    "\n",
    "    model = Model(resnet_base.input, x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Simple_U_Net Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import multi_gpu_model\n",
    "from keras.backend.tensorflow_backend import set_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import mse, binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/data/severstal-steel-defect-detection/'\n",
    "train_df = pd.read_csv(base_dir+'/train.csv')\n",
    "train_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "train_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\n",
    "train_df['hasMask'] = ~ train_df['EncodedPixels'].isna()\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_count_df = train_df.groupby('ImageId').agg(np.sum).reset_index()\n",
    "mask_count_df.sort_values('hasMask', ascending=False, inplace=True)\n",
    "print(mask_count_df.shape)\n",
    "mask_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(base_dir+'/sample_submission.csv')\n",
    "sub_df['ImageId'] = sub_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "test_imgs = pd.DataFrame(sub_df['ImageId'].unique(), columns=['ImageId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle2mask(mask_rle, shape=(1600,256)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (width,height) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_masks(rles, input_shape):\n",
    "    depth = len(rles)\n",
    "    height, width = input_shape\n",
    "    masks = np.zeros((height, width, depth))\n",
    "    \n",
    "    for i, rle in enumerate(rles):\n",
    "        if type(rle) is str:\n",
    "            masks[:, :, i] = rle2mask(rle, (width, height))\n",
    "    \n",
    "    return masks\n",
    "\n",
    "def build_rles(masks):\n",
    "    width, height, depth = masks.shape\n",
    "    \n",
    "    rles = [mask2rle(masks[:, :, i])\n",
    "            for i in range(depth)]\n",
    "    \n",
    "    return rles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n",
    "                 base_path= base_dir+'train_images',\n",
    "                 batch_size=32, dim=(256, 1600), n_channels=1,\n",
    "                 n_classes=4, random_state=2019, shuffle=True, preprocess=None):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "        self.base_path = base_path\n",
    "        self.target_df = target_df\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "        self.preprocess = preprocess\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n",
    "        \n",
    "        X = self.__generate_X(list_IDs_batch)\n",
    "        \n",
    "        if self.mode == 'fit':\n",
    "            y = self.__generate_y(list_IDs_batch)\n",
    "            return X, y\n",
    "        \n",
    "        elif self.mode == 'predict':\n",
    "            return X\n",
    "\n",
    "        else:\n",
    "            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.seed(self.random_state)\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __generate_X(self, list_IDs_batch):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            im_name = self.df['ImageId'].iloc[ID]\n",
    "            img_path = \"{}/{}\".format(self.base_path, im_name)\n",
    "            img = self.__load_rgb(img_path)\n",
    "            \n",
    "            if self.preprocess: img = self.preprocess(img)\n",
    "            \n",
    "            # Store samples\n",
    "            X[i,] = img\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def __generate_y(self, list_IDs_batch):\n",
    "        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            im_name = self.df['ImageId'].iloc[ID]\n",
    "            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n",
    "            \n",
    "            rles = image_df['EncodedPixels'].values\n",
    "            masks = build_masks(rles, input_shape=self.dim)\n",
    "            \n",
    "            y[i, ] = masks\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def __load_grayscale(self, img_path):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = img.astype(np.float32) / 255.\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "\n",
    "        return img\n",
    "    \n",
    "    def __load_rgb(self, img_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32) / 255.\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/data/severstal-steel-defect-detection/train_images/'+train_df.ImageId.values[0]\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    mask_count_df.index, random_state=2019, test_size=0.15\n",
    ")\n",
    "\n",
    "train_generator = DataGenerator(\n",
    "    train_idx, \n",
    "    df=mask_count_df,\n",
    "    target_df=train_df,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    n_classes=4,\n",
    "    n_channels=3\n",
    ")\n",
    "\n",
    "val_generator = DataGenerator(\n",
    "    val_idx, \n",
    "    df=mask_count_df,\n",
    "    target_df=train_df,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    n_classes=4,\n",
    "    n_channels=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, freeze_encoder, classes):\n",
    "    \n",
    "    with tf.device('/cpu:0'):\n",
    "        resnet_base = Unet(\n",
    "                                   backbone_name='resnext50',\n",
    "                                   input_shape=input_shape,\n",
    "#                                    input_tensor=None,\n",
    "                                   encoder_weights='imagenet',\n",
    "                                   freeze_encoder=freeze_encoder,\n",
    "                                   skip_connections='default',\n",
    "                                   decoder_block_type='transpose',\n",
    "                                   decoder_filters=(128, 64, 32, 16, 8),\n",
    "                                   decoder_use_batchnorm=True,\n",
    "                                   n_upsample_blocks=5,\n",
    "#                                    upsample_rates=(2, 2, 2, 2, 2),\n",
    "                                   classes=classes,\n",
    "                                   activation='sigmoid')\n",
    "\n",
    "        x = SpatialDropout2D(0.2)(resnet_base.output)\n",
    "        x = Conv2D(1, (1, 1), activation=\"sigmoid\", name=\"prediction\")(x)\n",
    "\n",
    "        model = Model(resnet_base.input, x)\n",
    "    \n",
    "    parallel_model = multi_gpu_model(model, gpus=8)\n",
    "    parallel_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n",
    "    \n",
    "    del model\n",
    "    \n",
    "    return parallel_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model((256, 1600, 3), True, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'model.h5', \n",
    "    monitor='val_loss', \n",
    "    verbose=0, \n",
    "    save_best_only=True, \n",
    "    save_weights_only=False,\n",
    "    mode='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[checkpoint],\n",
    "#     use_multiprocessing=True,\n",
    "#     workers=4,\n",
    "    epochs=25,\n",
    "#     class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models import Unet\n",
    "from segmentation_models.backbones import get_preprocessing\n",
    "\n",
    "# LOAD UNET WITH PRETRAINING FROM IMAGENET\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    preprocess = get_preprocessing('resnet34') # for resnet, img = (img-110.0)/1.0\n",
    "    model = Unet('resnet34', input_shape=(256, 1600, 3), classes=4, activation='sigmoid')\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n",
    "\n",
    "parallel_model = multi_gpu_model(model, gpus=8)\n",
    "parallel_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    mask_count_df.index, random_state=2019, test_size=0.15\n",
    ")\n",
    "\n",
    "train_generator = DataGenerator(\n",
    "    train_idx, \n",
    "    df=mask_count_df,\n",
    "    target_df=train_df,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    n_classes=4,\n",
    "    n_channels=3,\n",
    "    preprocess=preprocess\n",
    ")\n",
    "\n",
    "val_generator = DataGenerator(\n",
    "    val_idx, \n",
    "    df=mask_count_df,\n",
    "    target_df=train_df,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    n_classes=4,\n",
    "    n_channels=3,\n",
    "    preprocess=preprocess\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'model.h5', \n",
    "    monitor='val_loss', \n",
    "    verbose=0, \n",
    "    save_best_only=True, \n",
    "    save_weights_only=False,\n",
    "    mode='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = parallel_model.fit_generator(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[checkpoint],\n",
    "#     use_multiprocessing=True,\n",
    "#     workers=4,\n",
    "    epochs=25,\n",
    "#     class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
